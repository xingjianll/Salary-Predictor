{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T22:08:07.309599Z",
     "start_time": "2024-04-17T22:08:02.606597Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import read_csv_data, clean_location\n",
    "\n",
    "data = read_csv_data(\"../data/processed_job_postings_large.csv\", \n",
    "                     [\"industry\", \"work_type\", \"location\", \"formatted_experience_level\",\n",
    "                      \"name\", \"cleaned_title\", \"cleaned_description\"],\n",
    "                     \"standardized_annual_salary\")\n",
    "data = clean_location(data, 2)\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(data)\n",
    "\n",
    "train_data = data[:20000]\n",
    "val_data = data[20000:30000]\n",
    "test_data = data[30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72692612c9cf88a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T22:08:07.729291Z",
     "start_time": "2024-04-17T22:08:07.312200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import build_column_vocabulary\n",
    "\n",
    "vocab_industry = build_column_vocabulary(train_data, 0)\n",
    "vocab_type = build_column_vocabulary(train_data, 1)\n",
    "vocab_state = build_column_vocabulary(train_data, 2)\n",
    "vocab_level = build_column_vocabulary(train_data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4fd8830c588f794",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T22:08:16.647245Z",
     "start_time": "2024-04-17T22:08:07.731693Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import convert_to_one_hot\n",
    "import torch\n",
    "\n",
    "train_cat_features = convert_to_one_hot(train_data, \n",
    "                                  [(0, vocab_industry),\n",
    "                                   (1, vocab_type),\n",
    "                                   (2, vocab_state),\n",
    "                                   (3, vocab_level)])\n",
    "\n",
    "val_cat_features = convert_to_one_hot(val_data, \n",
    "                                  [(0, vocab_industry),\n",
    "                                   (1, vocab_type),\n",
    "                                   (2, vocab_state),\n",
    "                                   (3, vocab_level)])\n",
    "\n",
    "# Convert Lists to Tensors\n",
    "train_cat_features = torch.stack(train_cat_features)\n",
    "val_cat_features = torch.stack(val_cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d1c3502cb523762",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T22:08:17.618947Z",
     "start_time": "2024-04-17T22:08:16.649579Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-gpt\")\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "tokenizer.padding_side = \"right\" \n",
    "a = tokenizer('hello this is a test',\n",
    "         truncation=True,\n",
    "         padding='max_length',\n",
    "         max_length=512,\n",
    "         return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f09d5233be3f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T22:09:07.581054Z",
     "start_time": "2024-04-17T22:08:17.620608Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from gpt1 import GPT1Dataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "descriptions = [item[0][6] for item in train_data]\n",
    "input_ids, attention_mask = [], []\n",
    "for description in descriptions:\n",
    "    encoding = tokenizer(description,\n",
    "                         truncation=True,\n",
    "                         padding='max_length',\n",
    "                         max_length=512,\n",
    "                         return_tensors=\"pt\")\n",
    "    # input_ids.append(encoding['input_ids'].squeeze())\n",
    "    # attention_mask.append(encoding['attention_mask'].squeeze())\n",
    "    input_ids.append(encoding['input_ids'][0])\n",
    "    attention_mask.append(encoding['attention_mask'][0])\n",
    "\n",
    "# Convert Lists to Tensors\n",
    "input_ids = torch.stack(input_ids)\n",
    "attention_mask = torch.stack(attention_mask)    \n",
    "\n",
    "labels = [float(target) for _, target in train_data]\n",
    "\n",
    "train_dataset = GPT1Dataset(input_ids, attention_mask, train_cat_features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "206cac4e80e854b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T22:09:07.594531Z",
     "start_time": "2024-04-17T22:09:07.582681Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([ 6303,  5253, 23263,   640,  5154,   562,  4387,   488, 33243, 12810,\n",
       "           485,  8052,   600,   640,  7826,   500,   246, 32968,  6425,   488,\n",
       "          2029, 14121,  1996,  7404,   481,  5253,  6844,   485,  2236,   488,\n",
       "         12561,   746,  5253,  9535,  6672,  8153,  2694,  8017,  6112,   488,\n",
       "          1178, 40443, 20369,  5655,   481,  2179,  9269,  6875,  2906,   555,\n",
       "          9514,  6875,   544,   566,   498,   481,  1495, 26789,  3304, 31375,\n",
       "           500,   481,  6391,  7876,   600,   640,  1081,   562,   531,  5007,\n",
       "          6303,  5253,  6844,   485,  3351,   754,  3170,  2855,   556,   531,\n",
       "          6636,  6271, 39135,   745,   562,  4804, 10361,   488,  2429,   616,\n",
       "          7391,   500, 35627,   562,   754,  6589,  1463,   488, 10998,  8426,\n",
       "         18298, 19231,  3388,  1510,  1383, 12602, 14152, 28530,   488,  6190,\n",
       "           519,  2102,  5142,  7730,   517,  1801, 22537,  5253, 11675, 16680,\n",
       "           488,  3675,   485,  9945,   720,  4317, 19005, 23006, 20011,   562,\n",
       "         36060,  5253,  3669, 10760, 21403,   488, 14799,  7242,   498,  5467,\n",
       "          9535,   485,  4640,  6126,  1227,   498, 12622,     3, 39994,  9807,\n",
       "           556,  1840, 31375,   488, 39733, 15450,   498,  1840, 31375,   525,\n",
       "          9036,  7410,  5847,   625, 12700,   556,  5253,  3997,   485, 10424,\n",
       "          1129,  2236,   488,   485, 27221,  9315, 14234,   488,  9777,   498,\n",
       "         19975,    15, 33414,   488, 19048,  9171,   498,  5253, 11553,   485,\n",
       "          8052,  5253,  4969,  1633,   504,  6816,   488,  2029, 27712,   545,\n",
       "          7678,     3, 37209,  6858, 15270, 19814,  6816,   485,  3937,   488,\n",
       "         13878,   481,  7049,  5253,  4986,  5001, 12811,   996,  7788,  7268,\n",
       "          3572,   702,  5253, 11553,   488, 13458, 14343, 22921,   522,  3675,\n",
       "           557, 15490,   970,   572,     3,  1917,   522, 37209,  5253,  7268,\n",
       "           562, 12128,  6875,   522,  3686, 16796, 12700,   556,  5253, 11553,\n",
       "           485,  6159, 15123,  5553,   488,   485,  9093,  1881,    20,   582,\n",
       "           506,   710,   552,   280,  1218,   498,  8426,  4010,    25,   859,\n",
       "            17,   731,  5614,   500,  6589,  1463, 10998,   625,  4710,  3388,\n",
       "          2074, 20316,   488,  3857,  8932, 22312,   582,   506,    12,  7169,\n",
       "           500,  6239,  2022,  1876,  5097,     5,   481,  3371,   485,  1129,\n",
       "           500,   246,  1708,  7948,  1129,  8412,  1448, 25719,   485,  1129,\n",
       "         29561,   488,   557,  1250,   498,   246, 18298,   481,  3183,   485,\n",
       "          4097,   754,  5784, 18320, 27187,   481,  3183,   485,  2413,   481,\n",
       "          9638,   498,   246,  6711, 30656,  3304,  9648,  1525,   481,  3183,\n",
       "           485, 13259,   803,   498,   481,  4066,  5253,  4510,   486,    14,\n",
       "          2074,  3921,  5319,   556,  6875,  2934, 11865,    14,  1890,  1067,\n",
       "           486,  3888, 16234,   498,    50, 12354, 12354,    53,    48,  7397,\n",
       "         11343,   504,  4010,  1345,  8912,  5945, 14402,  5295,   536,   501,\n",
       "          2600,  3999,   502,    15,  1708, 10103,  5784,  4969, 14890,  1463,\n",
       "         28242,  1047,   791,  2600,   952,   882, 21394,  1463,  6558,  8954,\n",
       "          1575,  4130,   539,  1019,   486,  5147,    15, 33538,   677,  1426,\n",
       "         24744,    39,   265,  2236,   556,  2600, 31190, 10114,  6074,   488,\n",
       "          3282,   280,  1218,   498,  8426,  3282,  2074,  5614,   500,  6589,\n",
       "          1463, 10998,  8426,  2074, 20316,   488,  3857,  8932,  6074, 32278,\n",
       "           500,  6239,  2022,  1876,  6902,   481,  3371,   485,  1129,   500,\n",
       "           246,  1708,  7948,  1129,  9961,  3371,   485,  1129, 29561,   488,\n",
       "           557,  1250,   498,   246,  2855,   481,  3183,   485,  4097,   754,\n",
       "          5784, 22048,   481,  3183,   485,  2413,   481,  9638,   498,   246,\n",
       "          6711, 30656,  3304, 24948,   481,  3183,   485, 13259,   803,   498,\n",
       "           481,  4066,  5253, 23263,  2074,  3921,  5319,   556,  6875,  9807,\n",
       "           787,   249,  1056,   595, 25692, 22023,   504,   481,  9351,   498,\n",
       "          4115,  3184]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'categorical_features': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0.]),\n",
       " 'labels': tensor(80000.)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8accdb120e1c74a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T22:09:07.752072Z",
     "start_time": "2024-04-17T22:09:07.597726Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jimmyhao/Desktop/UT/CSC413/Salary-Predictor/.conda/lib/python3.11/site-packages/transformers/training_args.py:1399: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of 🤗 Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# copied from https://colab.research.google.com/drive/1PEQyJO1-f6j0S_XJ8DV50NkpzasXkrzd?usp=sharing\n",
    "# Activate 4-bit precision base model loading\n",
    "# use_4bit = True\n",
    "use_4bit = False\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "# bnb_4bit_compute_dtype = \"float16\"\n",
    "bnb_4bit_compute_dtype = \"float32\"\n",
    "\n",
    "################################################################################\n",
    "# QLoRA parameters\n",
    "################################################################################\n",
    "\n",
    "# LoRA attention dimension\n",
    "lora_r = 64\n",
    "\n",
    "# Alpha parameter for LoRA scaling\n",
    "lora_alpha = 16\n",
    "\n",
    "# Dropout probability for LoRA layers\n",
    "lora_dropout = 0.1\n",
    "# Output directory where the model predictions and checkpoints will be stored\n",
    "output_dir = \"./results\"\n",
    "\n",
    "# Number of training epochs\n",
    "num_train_epochs = 1\n",
    "\n",
    "# Enable fp16/bf16 training (set bf16 to True with an A100)\n",
    "fp16 = False\n",
    "bf16 = False\n",
    "\n",
    "# Batch size per GPU for training\n",
    "per_device_train_batch_size = 4\n",
    "\n",
    "# Batch size per GPU for evaluation\n",
    "per_device_eval_batch_size = 4\n",
    "\n",
    "# Number of update steps to accumulate the gradients for\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "gradient_checkpointing = True\n",
    "\n",
    "# Maximum gradient normal (gradient clipping)\n",
    "max_grad_norm = 0.3\n",
    "\n",
    "# Initial learning rate (AdamW optimizer)\n",
    "learning_rate = 2e-4\n",
    "\n",
    "# Weight decay to apply to all layers except bias/LayerNorm weights\n",
    "weight_decay = 0.001\n",
    "\n",
    "# Optimizer to use\n",
    "optim = \"paged_adamw_32bit\"\n",
    "\n",
    "# Learning rate schedule\n",
    "lr_scheduler_type = \"cosine\"\n",
    "\n",
    "# Number of training steps (overrides num_train_epochs)\n",
    "max_steps = -1\n",
    "\n",
    "# Ratio of steps for a linear warmup (from 0 to learning rate)\n",
    "warmup_ratio = 0.03\n",
    "\n",
    "# Group sequences into batches with same length\n",
    "# Saves memory and speeds up training considerably\n",
    "group_by_length = True\n",
    "\n",
    "# Save checkpoint every X updates steps\n",
    "save_steps = 0\n",
    "\n",
    "# Log every X updates steps\n",
    "logging_steps = 25\n",
    "\n",
    "from peft import LoraConfig\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# \n",
    "# Load tokenizer and model with QLoRA configuration\n",
    "# compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "# \n",
    "# Check GPU compatibility with bfloat16\n",
    "# if compute_dtype == torch.float16 and use_4bit:\n",
    "#     major, _ = torch.cuda.get_device_capability()\n",
    "#     if major >= 8:\n",
    "#         print(\"=\" * 80)\n",
    "#         print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "#         print(\"=\" * 80)\n",
    "\n",
    "# Load LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"c_attn\", \"c_proj\"],\n",
    "    fan_in_fan_out=True\n",
    ")\n",
    "\n",
    "# Set training parameters\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    fp16=fp16,\n",
    "    bf16=bf16,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=group_by_length,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    no_cuda=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6025166c04034571",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T22:09:09.745332Z",
     "start_time": "2024-04-17T22:09:07.753750Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gpt1 import GPT1\n",
    "\n",
    "model = GPT1(len(vocab_type) + len(vocab_industry) + len(vocab_state) + len(vocab_level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f9ccf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([20000, 512])\n",
      "<class 'torch.Tensor'> torch.Size([20000, 512])\n",
      "<class 'torch.Tensor'> torch.Size([20000, 307])\n"
     ]
    }
   ],
   "source": [
    "print(type(input_ids), input_ids.shape)\n",
    "print(type(attention_mask), attention_mask.shape)\n",
    "print(type(train_cat_features), train_cat_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7194e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'labels' key missing in batch 0\n",
      "Error: 'labels' key missing in batch 1\n",
      "Error: 'labels' key missing in batch 2\n",
      "Error: 'labels' key missing in batch 3\n",
      "Error: 'labels' key missing in batch 4\n",
      "Error: 'labels' key missing in batch 5\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from gpt1 import collate_batch\n",
    "\n",
    "data_loader = DataLoader(train_dataset, batch_size=4, collate_fn=collate_batch, shuffle=True)\n",
    "\n",
    "# Test run through the DataLoader to print and check batch contents\n",
    "for idx, batch in enumerate(data_loader):\n",
    "    if 'labels' not in batch:\n",
    "        print(f\"Error: 'labels' key missing in batch {idx}\")\n",
    "    else:\n",
    "        print(f\"Batch {idx}: Contains 'labels' with shape {batch['labels'].shape}\")\n",
    "    if idx == 5:  # Check only the first 3 batches\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6965d2b76981fe9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T22:09:12.470121Z",
     "start_time": "2024-04-17T22:09:09.748696Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6fbd38496d4fe39029356338f3fa4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'cget_managed_ptr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 12\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[1;32m      4\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      5\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      6\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_arguments,\n\u001b[1;32m      7\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[1;32m      8\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mcollate_batch,\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/UT/CSC413/Salary-Predictor/.conda/lib/python3.11/site-packages/transformers/trainer.py:1780\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1778\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/UT/CSC413/Salary-Predictor/.conda/lib/python3.11/site-packages/transformers/trainer.py:2181\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2178\u001b[0m         grad_norm \u001b[38;5;241m=\u001b[39m _grad_norm\n\u001b[1;32m   2180\u001b[0m \u001b[38;5;66;03m# Optimizer step\u001b[39;00m\n\u001b[0;32m-> 2181\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2182\u001b[0m optimizer_was_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39moptimizer_step_was_skipped\n\u001b[1;32m   2183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer_was_run:\n\u001b[1;32m   2184\u001b[0m     \u001b[38;5;66;03m# Delay optimizer scheduling until metrics are generated\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/UT/CSC413/Salary-Predictor/.conda/lib/python3.11/site-packages/accelerate/optimizer.py:149\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 149\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator_state\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mXLA:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_state\u001b[38;5;241m.\u001b[39mis_xla_gradients_synced \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/UT/CSC413/Salary-Predictor/.conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/UT/CSC413/Salary-Predictor/.conda/lib/python3.11/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/UT/CSC413/Salary-Predictor/.conda/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/UT/CSC413/Salary-Predictor/.conda/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py:266\u001b[0m, in \u001b[0;36mOptimizer8bit.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    264\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate[p]\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(state) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefetch_state(p)\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_step(group, p, gindex, pindex)\n",
      "File \u001b[0;32m~/Desktop/UT/CSC413/Salary-Predictor/.conda/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/UT/CSC413/Salary-Predictor/.conda/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py:401\u001b[0m, in \u001b[0;36mOptimizer2State.init_state\u001b[0;34m(self, group, p, gindex, pindex)\u001b[0m\n\u001b[1;32m    396\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat32 \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    399\u001b[0m     dtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39muint8 \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m4096\u001b[39m\n\u001b[1;32m    400\u001b[0m ):\n\u001b[0;32m--> 401\u001b[0m     state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_state_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m     state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate2\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_state_buffer(p, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39muint8:\n",
      "File \u001b[0;32m~/Desktop/UT/CSC413/Salary-Predictor/.conda/lib/python3.11/site-packages/bitsandbytes/optim/optimizer.py:309\u001b[0m, in \u001b[0;36mOptimizer8bit.get_state_buffer\u001b[0;34m(self, p, dtype)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mzeros_like(p, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mp\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;66;03m# > 1 MB\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m     buff \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_paged\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m     F\u001b[38;5;241m.\u001b[39mfill(buff, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpage_mng\u001b[38;5;241m.\u001b[39mpaged_tensors\u001b[38;5;241m.\u001b[39mappend(buff)\n",
      "File \u001b[0;32m~/Desktop/UT/CSC413/Salary-Predictor/.conda/lib/python3.11/site-packages/bitsandbytes/functional.py:171\u001b[0m, in \u001b[0;36mget_paged\u001b[0;34m(dtype, device, *shape)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_paged\u001b[39m(\u001b[38;5;241m*\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)):\n\u001b[1;32m    170\u001b[0m     num_bytes \u001b[38;5;241m=\u001b[39m dtype2bytes[dtype]\u001b[38;5;241m*\u001b[39mprod(shape)\n\u001b[0;32m--> 171\u001b[0m     cuda_ptr \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcget_managed_ptr\u001b[49m(ct\u001b[38;5;241m.\u001b[39mc_size_t(num_bytes))\n\u001b[1;32m    172\u001b[0m     c_ptr \u001b[38;5;241m=\u001b[39m ct\u001b[38;5;241m.\u001b[39mcast(cuda_ptr, ct\u001b[38;5;241m.\u001b[39mPOINTER(ct\u001b[38;5;241m.\u001b[39mc_int))\n\u001b[1;32m    173\u001b[0m     new_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mctypeslib\u001b[38;5;241m.\u001b[39mas_array(c_ptr, shape\u001b[38;5;241m=\u001b[39mshape)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'cget_managed_ptr'"
     ]
    }
   ],
   "source": [
    "from gpt1 import collate_batch\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=collate_batch,\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db1dcc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
